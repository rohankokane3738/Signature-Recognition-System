{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nimport numpy as np\nfrom keras import backend as K\nimport cv2\nimport matplotlib.pyplot as plt\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.regularizers import l2\nfrom keras.optimizers import Adam\nfrom keras.optimizers import SGD\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":76,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_dir=\"/kaggle/input/signature-verification-dataset/sign_data/train\"\ntrain_csv=\"/kaggle/input/signature-verification-dataset/sign_data/train_data.csv\"\ntest_csv=\"/kaggle/input/signature-verification-dataset/sign_data/test_data.csv\"\ntest_dir=\"/kaggle/input/signature-verification-dataset/sign_data/test\"","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train=pd.read_csv(train_csv)\ndf_train.sample(10)","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"       068/09_068.png  068_forg/03_0113068.PNG  1\n16912  020/05_020.png           020/09_020.png  0\n18187  015/015_18.PNG  015_forg/0213015_04.png  1\n12678  049/01_049.png  049_forg/04_0206049.PNG  1\n20464  056/06_056.png           056/02_056.png  0\n1562   045/09_045.png           045/05_045.png  0\n13788  018/03_018.png  018_forg/02_0106018.PNG  1\n7408   065/02_065.png  065_forg/02_0206065.PNG  1\n1826   038/02_038.png           038/06_038.png  0\n19205  042/04_042.png           042/07_042.png  0\n3921   014/014_03.PNG  014_forg/0214014_03.png  1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>068/09_068.png</th>\n      <th>068_forg/03_0113068.PNG</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16912</th>\n      <td>020/05_020.png</td>\n      <td>020/09_020.png</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18187</th>\n      <td>015/015_18.PNG</td>\n      <td>015_forg/0213015_04.png</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12678</th>\n      <td>049/01_049.png</td>\n      <td>049_forg/04_0206049.PNG</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20464</th>\n      <td>056/06_056.png</td>\n      <td>056/02_056.png</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1562</th>\n      <td>045/09_045.png</td>\n      <td>045/05_045.png</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13788</th>\n      <td>018/03_018.png</td>\n      <td>018_forg/02_0106018.PNG</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7408</th>\n      <td>065/02_065.png</td>\n      <td>065_forg/02_0206065.PNG</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1826</th>\n      <td>038/02_038.png</td>\n      <td>038/06_038.png</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19205</th>\n      <td>042/04_042.png</td>\n      <td>042/07_042.png</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3921</th>\n      <td>014/014_03.PNG</td>\n      <td>014_forg/0214014_03.png</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dataset_train(train_csvfile):\n    x1=[]\n    x2=[]\n    y_train=[]\n    for i in range(0,2000):\n        image1_path=os.path.join(train_dir,train_csvfile.iat[i,0])\n        image2_path=os.path.join(train_dir,train_csvfile.iat[i,1])\n        img1=cv2.imread(image1_path)\n        img1= cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n        img1=cv2.resize(img1,(150,150))\n        x1.append(img1)\n        img2=cv2.imread(image2_path)\n        img2= cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n        img2=cv2.resize(img2,(150,150))\n        x2.append(img2)\n        y_train.append(train_csvfile.iat[i,2])\n#         print(i)\n#         l.append([img1,img2,train_csvfile.iat[i,2]])\n    x1=np.array(x1).astype(np.float32)/255.0\n    x2=np.array(x2).astype(np.float32)/255.0\n    y_train=np.array(y_train).astype(np.float32)\n    \n    return x1,x2,y_train","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dataset_test(test_csvfile):\n    x1=[]\n    x2=[]\n    y_train=[]\n    for i in range(2000,4000):\n        image1_path=os.path.join(test_dir,test_csvfile.iat[i,0])\n        image2_path=os.path.join(test_dir,test_csvfile.iat[i,1])\n        img1=cv2.imread(image1_path)\n        img1= cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n        img1=cv2.resize(img1,(150,150))\n        x1.append(img1)\n        img2=cv2.imread(image2_path)\n        img2= cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n        img2=cv2.resize(img2,(150,150))\n        x2.append(img2)\n        y_train.append(test_csvfile.iat[i,2])\n#         print(i)\n#         l.append([img1,img2,train_csvfile.iat[i,2]])\n    x1=np.array(x1).astype(np.float32)/255.0\n    x2=np.array(x2).astype(np.float32)/255.0\n    y_train=np.array(y_train).astype(np.float32)\n    \n    return x1,x2,y_train","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test=pd.read_csv(test_csv)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xt1,xt2,yt=dataset_test(df_test)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xs1,xs2,ys=dataset_train(df_train)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef dist1(xy):\n    x, y = xy\n    sum_abs = K.sum(K.abs(x - y), axis=1, keepdims=True)\n#     return sum_abs\n    return K.maximum(sum_abs, K.epsilon())\ndef dist2(xy):\n    x,y=xy\n    sum_square=K.sum(K.square(x-y),axis=1,keepdims=True)\n    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n\ndef dist3(xy):\n    x,y=xy\n    return K.sqrt(K.mean(K.square(x-y),axis=1,keepdims=True))\ndef dist4(xy):\n    x,y=xy\n    ss=K.sum(K.square(x-y),axis=1,keepdims=True)\n    return K.sqrt(ss)/x.shape[1]\n\n\ninput1=keras.layers.Input(shape=(150,150,1))\n# x=keras.layers.Flatten()(input1)\nx=keras.layers.Conv2D(64,(10,10),activation='relu')(input1)\nx=keras.layers.MaxPooling2D(2,2)(x)\n# x=BatchNormalization()(x)\nx=keras.layers.Dropout(0.5)(x)\n# x=keras.layers.Conv2D(128,(7,7),activation='relu')(x)\n# x=keras.layers.MaxPooling2D(2,2)(x)\nx=keras.layers.Conv2D(100,(7,7),activation='relu')(x)\n# x=BatchNormalization()(x)\nx=keras.layers.MaxPooling2D(2,2)(x)\nx=keras.layers.Dropout(0.5)(x)\n# x=keras.layers.Conv2D(258,(4,4),activation='relu')(x)\n# x=keras.layers.MaxPooling2D(2,2)(x)\nx=keras.layers.Flatten()(x)\n# x=keras.layers.Dense(4096,activation='relu')(x)\nx=keras.layers.Dense(500,activation='relu')(x)\n# x=BatchNormalization()(x)\ndense=keras.models.Model(inputs=input1,outputs=x)\n\n\nimg1=keras.layers.Input(shape=(150,150,1))\nimg2=keras.layers.Input(shape=(150,150,1))\ndense1=dense(img1)\ndense2=dense(img2)\nfc=keras.layers.Lambda(dist3)([dense1,dense2])\n# fc=keras.layers.Dense(100,activation='relu')(fc)\nfc=keras.layers.Dense(1,activation='sigmoid')(fc)\n\nm=keras.models.Model(inputs=[img1,img2],outputs=fc)\n\nm.compile(loss = \"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\nm.summary()\n\n    ","execution_count":85,"outputs":[{"output_type":"stream","text":"Model: \"functional_127\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_98 (InputLayer)           [(None, 150, 150, 1) 0                                            \n__________________________________________________________________________________________________\ninput_99 (InputLayer)           [(None, 150, 150, 1) 0                                            \n__________________________________________________________________________________________________\nfunctional_125 (Functional)     (None, 500)          51520664    input_98[0][0]                   \n                                                                 input_99[0][0]                   \n__________________________________________________________________________________________________\nlambda_31 (Lambda)              (None, 1)            0           functional_125[0][0]             \n                                                                 functional_125[1][0]             \n__________________________________________________________________________________________________\ndense_75 (Dense)                (None, 1)            2           lambda_31[0][0]                  \n==================================================================================================\nTotal params: 51,520,666\nTrainable params: 51,520,666\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.fit([xs1,xs2],ys,epochs=10)","execution_count":86,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n63/63 [==============================] - 5s 77ms/step - loss: 0.6838 - accuracy: 0.5380\nEpoch 2/10\n63/63 [==============================] - 5s 80ms/step - loss: 0.5373 - accuracy: 0.5745\nEpoch 3/10\n63/63 [==============================] - 5s 78ms/step - loss: 0.4549 - accuracy: 0.6945\nEpoch 4/10\n63/63 [==============================] - 5s 77ms/step - loss: 0.3989 - accuracy: 0.8025\nEpoch 5/10\n63/63 [==============================] - 5s 77ms/step - loss: 0.3539 - accuracy: 0.8770\nEpoch 6/10\n63/63 [==============================] - 5s 76ms/step - loss: 0.3268 - accuracy: 0.9250\nEpoch 7/10\n63/63 [==============================] - 5s 77ms/step - loss: 0.3014 - accuracy: 0.9660\nEpoch 8/10\n63/63 [==============================] - 5s 78ms/step - loss: 0.2802 - accuracy: 0.9805\nEpoch 9/10\n63/63 [==============================] - 5s 78ms/step - loss: 0.2649 - accuracy: 0.9905\nEpoch 10/10\n63/63 [==============================] - 5s 77ms/step - loss: 0.2506 - accuracy: 0.9910\n","name":"stdout"},{"output_type":"execute_result","execution_count":86,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f0122a74610>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.evaluate([xt1,xt2],yt)","execution_count":87,"outputs":[{"output_type":"stream","text":"63/63 [==============================] - 1s 18ms/step - loss: 0.3375 - accuracy: 0.9060\n","name":"stdout"},{"output_type":"execute_result","execution_count":87,"data":{"text/plain":"[0.3374583125114441, 0.906000018119812]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def check(stored,image):\n    img2=np.array([image])\n    for i in range(0,stored.shape[0]):\n        img1=np.array([stored[i]])\n        pred=m.predict([img1,img2])\n        print(pred)\n        if(pred<0.5):\n            print(\"matched\",i)\n            return\n    print(\"unmatched\")\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"database_signatures=xt1[:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check(database_signatures,xt1[13])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(xs1[223])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(xt1[223])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}